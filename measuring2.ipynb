{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN Species Measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.whales import whale\n",
    "\n",
    "import numpy.ma as ma\n",
    "import scipy.misc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.filters\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 17\n",
      "Classes: ['BG', 'megaptera_novaeangliae_body', 'megaptera_novaeangliae_pectoral']\n"
     ]
    }
   ],
   "source": [
    "#sets up the system and generates masks\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "%matplotlib inline \n",
    "\n",
    "# Path to trained weights\n",
    "#WHALE_WEIGHTS_PATH = \"/home/clifgray/Code/Mask_RCNN/logs/whale20180613T0247/mask_rcnn_whale_0075.h5\"\n",
    "\n",
    "config = whale.WhaleConfig()\n",
    "WHALE_DIR = os.path.join(ROOT_DIR, \"datasets/whale_training/blue\")\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "# Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "#config.display()\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "# Load validation dataset\n",
    "dataset = whale.WhaleDataset()\n",
    "dataset.load_whale(WHALE_DIR, \"test\")\n",
    "#\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "\n",
    "\n",
    "#Getting manually drawn masks\n",
    "id_array = np.arange(len(dataset.image_ids)) #17 images in this set\n",
    "mask_array = []\n",
    "for num in id_array:\n",
    "    image_id = num\n",
    "\n",
    "    image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    info = dataset.image_info[image_id]\n",
    "   # if image_id >= 19 and image_id <= 35:\n",
    "    mask_array.append(mask)\n",
    "    \n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(weights_path=\"/home/clifgray/Code/Mask_RCNN/logs/whale20180613T0247/mask_rcnn_whale_0150.h5\"):\n",
    "    # Create model in inference mode\n",
    "    with tf.device(DEVICE):\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "        \n",
    "    # Load weights\n",
    "    print(\"Loading weights \", weights_path)\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    print(\"Weights loaded.\")\n",
    "    \n",
    "    \n",
    "    detection_results = []\n",
    "    initial_time = time.perf_counter()\n",
    "    for image_id in dataset.image_ids:\n",
    "    \n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "\n",
    "        info = dataset.image_info[image_id]\n",
    "\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        \n",
    "        detection_results.append([results, info, image_id])\n",
    "        print(\"Done detecting and masking image #:  \" + str(len(detection_results)))\n",
    "    \n",
    "    finish_time = time.perf_counter()\n",
    "    time_elapsed = finish_time - initial_time\n",
    "    print(\"\\n\")\n",
    "    print(time_elapsed, \"seconds elapsed while masking\", len(detection_results), \"images.\")\n",
    "    print((time_elapsed/len(detection_results), \"seconds per image.\"))\n",
    "    \n",
    "    return detection_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each image could have multiple masks (body and pectoral)\n",
    "#Only done with the manually drawn masks\n",
    "\n",
    "def find_correct_mask(mask): \n",
    "    #Find which mask to use - one with the largest number of pixels\n",
    "    # TODO change this to choosing the ones with the body label\n",
    "    numOfMasks = np.size(mask, 2)\n",
    "    i = 0\n",
    "    pixcount = 0\n",
    "    pixCountArray = []\n",
    "    while i < numOfMasks:\n",
    "        currentMask = (mask[:, :, i])\n",
    "        pixcount = 0\n",
    "        nonzero = np.nonzero(currentMask)\n",
    "        it2 = np.nditer(currentMask, flags =['multi_index'])\n",
    "        while not it2.finished:\n",
    "            if it2[0] == True:\n",
    "                pixcount = pixcount + 1\n",
    "            it2.iternext()\n",
    "        pixCountArray.append(pixcount)\n",
    "        i = i+1\n",
    "\n",
    "#Find max in pixCountArray - gets the biggest mask that will be the body\n",
    "    correctIndex = pixCountArray.index(max(pixCountArray))\n",
    "    body = (mask[:,:,correctIndex])\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(body, boolean):\n",
    "    xy_array = []\n",
    " # get indexes of mask pixels\n",
    "    y, x = np.nonzero(body)\n",
    "    \n",
    "# mean center the coords\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    coords = np.vstack([x, y])\n",
    "\n",
    "# build covariance matreix and eigenvectors\n",
    "    cov = np.cov(coords)\n",
    "    evals, evecs = np.linalg.eig(cov)\n",
    "    \n",
    "# sort eigenvalues\n",
    "    sort_indices = np.argsort(evals)[::-1]\n",
    "    x_v1, y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "    x_v2, y_v2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "    \n",
    "    if boolean == True:\n",
    "# plot the major and minor axis of the whale mask\n",
    "        scale = 20\n",
    "        plt.plot(x, y, 'k.')\n",
    "\n",
    "        plt.plot([x_v1*-scale*2, x_v1*scale*2],\n",
    "         [y_v1*-scale*2, y_v1*scale*2], color='red')\n",
    "        plt.plot([x_v2*-scale, x_v2*scale],\n",
    "         [y_v2*-scale, y_v2*scale], color='blue')\n",
    "        plt.axis('equal')\n",
    "        plt.gca().invert_yaxis()  # Match the image system with origin at top left\n",
    "        plt.show()\n",
    "\n",
    "# orient this along the horizontal axis\n",
    "    theta = np.tanh((x_v2)/(y_v2))  \n",
    "    rotation_mat = np.matrix([[np.cos(theta), -np.sin(theta)],\n",
    "                      [np.sin(theta), np.cos(theta)]])\n",
    "    transformed_mat = rotation_mat * coords\n",
    "# plot the transformed blob\n",
    "#these are the final transformed coords\n",
    "    x_transformed, y_transformed = transformed_mat.A\n",
    "\n",
    "    maxX = np.max(x_transformed)\n",
    "    minX = np.min(x_transformed)\n",
    "    maxY = np.max(y_transformed)\n",
    "    minY = np.min(y_transformed)\n",
    "\n",
    "\n",
    "#Get corresonding Y values for minX and maxX\n",
    "    maxX_index = np.where(x_transformed == maxX) #index of right-most point\n",
    "    rightY = float((y_transformed[maxX_index])) #corresponding Y value\n",
    "\n",
    "\n",
    "    minX_index = np.where(x_transformed == minX) #index of left-most point\n",
    "    leftY = float((y_transformed[minX_index])) #corresponding Y value\n",
    "    \n",
    "#Orient the mask correctly - flip so the fluke is on the right\n",
    "\n",
    "#Get corresonding X values for maxY and minY\n",
    "\n",
    "    maxY_index = np.where(y_transformed == maxY) #index of top point\n",
    "    topX = float((x_transformed[maxY_index])) #corresponding X value\n",
    "\n",
    "\n",
    "    minY_index = np.where(y_transformed == minY) #index of bottom point\n",
    "    bottomX = float((x_transformed[minY_index])) #corresponding X value\n",
    "\n",
    "    #Flip mask so fluke is on the right, if necessary\n",
    "    if (topX < 0 or bottomX < 0):\n",
    "        x_transformed = x_transformed*-1 \n",
    "    \n",
    "    xy_array = [x_transformed, y_transformed]\n",
    "    \n",
    "    \n",
    "    return xy_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(results_list):\n",
    "    manual_length_list = []\n",
    "\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    \n",
    "    #Measuring process is repeated for each item in the array results_list\n",
    "    for item in results_list:\n",
    "        if np.array_equal(results_list, detection_results):\n",
    "            mask = item[0][0][\"masks\"]\n",
    "        else:\n",
    "            mask = item\n",
    "            \n",
    "        body = find_correct_mask(mask) #Ignore pectoral masks\n",
    "        xy_array = pca(body, False) #PCA, boolean argument determines if the images are shown during measuring\n",
    "        x_transformed = xy_array[0]\n",
    "        y_transformed = xy_array[1]\n",
    "        \n",
    "        #Reassign max/min X values in case image was flipped during PCA\n",
    "\n",
    "        maxX = np.max(x_transformed) #Right-most point\n",
    "        minX = np.min(x_transformed) #Left-most point\n",
    "\n",
    "#Get corresonding Y values for maxX and minX\n",
    "\n",
    "        maxX_index = np.where(x_transformed == maxX) #index of right-most point\n",
    "        rightY = float((y_transformed[maxX_index])) #corresponding Y value\n",
    "\n",
    "\n",
    "        minX_index = np.where(x_transformed == minX) #index of left-most point\n",
    "        leftY = float((y_transformed[minX_index])) #corresponding Y value\n",
    "        \n",
    "#Draw a straight line across the mask\n",
    "\n",
    "#Filter out points close to the midline of the mask (on the Y axis)\n",
    "    #Arbitrary lambda, might need to change later\n",
    "        lowEnough = list(filter(lambda y: y < (leftY + 0.5), y_transformed)) #above midline\n",
    "        yValues = list(filter(lambda y: y > (leftY - 0.5), lowEnough)) #below midline\n",
    "        yValues.sort()\n",
    "\n",
    "#Get corresponding X values to draw the line\n",
    "\n",
    "#List of appropriate indices\n",
    "        indices = []\n",
    "        for point in yValues:\n",
    "            index = int(np.where(y_transformed == point)[0])\n",
    "            indices.append(index)\n",
    "    \n",
    "        xValues = [] #Corresponding X values\n",
    "        for index in indices:\n",
    "            xValues.append(x_transformed[index]) \n",
    "\n",
    "        xValues.sort()\n",
    "\n",
    "        #Use distance formula to measure the length from the midline\n",
    "        length = math.sqrt((xValues[-1] - xValues[0])**2 + (yValues[-1] - yValues[0])**2)\n",
    "        \n",
    "       \n",
    "        if np.array_equal(results_list, detection_results): # Append to CNN object for auto-generated masks\n",
    "            item.append(length)\n",
    "        else:\n",
    "            manual_length_list.append(length) #Create and return a new list of lengths for manual masks\n",
    "        \n",
    "    \n",
    "    if np.array_equal(results_list, detection_results): # Append to CNN object\n",
    "        return\n",
    "    else:\n",
    "        return manual_length_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(whale_list, index): # Repeats and displays measuring without saving information, same as measure function\n",
    "    \n",
    "    image_id = index\n",
    "    \n",
    "    image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "        dataset, config, image_id, use_mini_mask=False)\n",
    "    log(\"molded_image\", image)\n",
    "    log(\"mask\", mask)\n",
    "    print(\"mask.shape\", mask.shape)\n",
    "    \n",
    "    item = whale_list[index]\n",
    "    if np.array_equal(whale_list, detection_results):\n",
    "        mask = item[0][0][\"masks\"]\n",
    "    else:\n",
    "        mask = item \n",
    "\n",
    "    visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names, show_bbox=False)\n",
    "    \n",
    "\n",
    "    length_list = []\n",
    "\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    \n",
    "    body = find_correct_mask(mask)\n",
    "    xy_array = pca(body, True)\n",
    "    x_transformed = xy_array[0]\n",
    "    y_transformed = xy_array[1]\n",
    "        \n",
    "\n",
    "    maxX = np.max(x_transformed)\n",
    "    minX = np.min(x_transformed) \n",
    "    \n",
    "\n",
    "\n",
    "    maxX_index = np.where(x_transformed == maxX) \n",
    "    rightY = float((y_transformed[maxX_index])) \n",
    "\n",
    "\n",
    "    minX_index = np.where(x_transformed == minX) \n",
    "    leftY = float((y_transformed[minX_index])) \n",
    "        \n",
    "        \n",
    "#Get points from leftX and rightX until it runs off the mask\n",
    "\n",
    "#Filter out points above straight horizontal midline \n",
    "    lowEnough = list(filter(lambda y: y < (leftY + 0.5), y_transformed))\n",
    "    yValues = list(filter(lambda y: y > (leftY - 0.5), lowEnough)) \n",
    "    yValues.sort()\n",
    "\n",
    "#Get corresponding X values\n",
    "    indices = []\n",
    "    for point in yValues:\n",
    "        index = int(np.where(y_transformed == point)[0])\n",
    "        indices.append(index)\n",
    "    \n",
    "    xValues = [] #Corresponding X values\n",
    "    for index in indices:\n",
    "        xValues.append(x_transformed[index]) \n",
    "\n",
    "    xValues.sort()\n",
    "\n",
    "    length = math.sqrt((xValues[-1] - xValues[0])**2 + (yValues[-1] - yValues[0])**2)\n",
    "\n",
    "\n",
    "    #Plot the midline used for measuring\n",
    "    plt.plot(x_transformed, y_transformed, 'g.', zorder=0)\n",
    "    \n",
    "    # set axis limits\n",
    "    plt.xlim([minX - 100, maxX + 100])\n",
    "    plt.ylim([leftY - 200, rightY + 200])\n",
    "    \n",
    "    #Plot the first and last points from the list, use this for length\n",
    "    \n",
    "    plt.scatter(xValues[0], yValues[0], zorder=10)\n",
    "    plt.scatter(xValues[-1], yValues[-1], zorder=10)\n",
    "    plt.scatter(xValues, yValues, zorder=10)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Length in Pixels:\", length)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_measurements(results_list):\n",
    "    excel_measurements = pd.read_excel(\"NSF-IOS_2017Measurements_kcb_updated_062018.xlsx\")\n",
    "    # Known measurements (imported from excel)\n",
    "    blue_measurements = excel_measurements.loc[excel_measurements[\"Whale\"].str.contains(\"Bm\")] \n",
    "    blue_measurements = blue_measurements.reset_index(drop=True)\n",
    "    manual_lengths = []\n",
    "    cnn_lengths = []\n",
    "\n",
    "# imaged were downsized from 6000 as a max dimension to 1024 as a max dimension so pixels are 5x as large in meters\n",
    "    pixel_size_factor = 6000.0 / 1024.0\n",
    "\n",
    "#measurements_df = pd.DataFrame(np.nan, index=np.arange(0, len(blue_measurements)), columns=['Filename', 'Auto_CNN_Measurements', 'Manual_Mask_Measurements', 'Manual_Standard_Measurements', 'Estimated_Manual_Error'])\n",
    "\n",
    "#measurements_df.set_index(\"Filename\")\n",
    "\n",
    "    for index, row in blue_measurements.iterrows():\n",
    "        cnn_pixel_count = 0\n",
    "        manual_pixel_count = 0\n",
    "    \n",
    "        total_altitude = row[\"Total Altitude\"]\n",
    "        pixel_size = row[\"Pixel size\"]\n",
    "        focal_length = row[\"Focal length (mm)\"] #always 5\n",
    "    \n",
    "        if np.array_equal(results_list, detection_results): \n",
    "            for whale in detection_results: #CNN Masks\n",
    "                if whale[1]['id'] == (row['Image']):\n",
    "                    cnn_pixel_count = whale[3]\n",
    "                    adjusted_cnn_pixel_count = cnn_pixel_count * pixel_size_factor\n",
    "                    cnn_length = adjusted_cnn_pixel_count * pixel_size/focal_length * total_altitude\n",
    "                    cnn_lengths.append(cnn_length)\n",
    "       \n",
    "        else: #Manual Masks\n",
    "            adjusted_manual_pixel_count = results_list[index] * pixel_size_factor\n",
    "            manual_length = adjusted_manual_pixel_count * pixel_size/focal_length * total_altitude\n",
    "            manual_lengths.append(manual_length)\n",
    "        \n",
    "    if np.array_equal(results_list, detection_results): \n",
    "        return cnn_lengths\n",
    "    else:\n",
    "        return manual_lengths\n",
    "\n",
    "    # TODO need to make this more robust, might not match the correct index at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def girth(results_list, length_list, num_of_increments):\n",
    "    \n",
    "    girth_measurements = []\n",
    "\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    \n",
    "    for item in results_list: #get the mask and length\n",
    "        if np.array_equal(results_list, detection_results):\n",
    "            mask = item[0][0][\"masks\"]\n",
    "            length = item[3]\n",
    "            img_id = item[2]\n",
    "        else:\n",
    "            mask = item\n",
    "            index = results_list.index(item)\n",
    "            length = length_list[index]\n",
    "            img_id = index\n",
    "            \n",
    "        body = find_correct_mask(mask) #Ignore pectoral masks\n",
    "        increment = length / num_of_increments\n",
    "        \n",
    "        xy_array = pca(body, False) #PCA\n",
    "        x_transformed = xy_array[0]\n",
    "        y_transformed = xy_array[1]\n",
    "        \n",
    "        print(\"Increment in Pixels\", increment)\n",
    "        \n",
    "        maxX = np.max(x_transformed)\n",
    "        minX = np.min(x_transformed)\n",
    "        maxY = np.max(y_transformed)\n",
    "        minY = np.min(y_transformed)\n",
    "        \n",
    "        plt.plot(x_transformed, y_transformed, 'g.', zorder=0)\n",
    "        \n",
    "        avgY = (sum(y_transformed) / len(y_transformed))\n",
    "        currentX = minX\n",
    "        \n",
    "        current_whale_girth = []\n",
    "        while(currentX < maxX-increment): \n",
    "            plt.scatter(currentX, avgY)\n",
    "            \n",
    "            \n",
    "            #At each X, filter out Y values from y_transformed to get vertical line\n",
    "                #Similar to measure()\n",
    "            #Filter out points close to vertical line \n",
    "\n",
    "            right_x_values = list(filter(lambda x: x < (currentX + 0.5), x_transformed))\n",
    "            xValues = list(filter(lambda x: x > (currentX - 0.5), right_x_values)) \n",
    "            xValues.sort()\n",
    "\n",
    "        #Get corresponding Y values to find top and bottom of line\n",
    "    #List of appropriate indices\n",
    "            indices = []\n",
    "            for point in xValues:\n",
    "                index = int(np.where(x_transformed == point)[0])\n",
    "                indices.append(index)\n",
    "    \n",
    "            yValues = [] #Corresponding X values\n",
    "            for index in indices:\n",
    "                yValues.append(y_transformed[index]) \n",
    "\n",
    "            yValues.sort()\n",
    "            plt.scatter(xValues, yValues, zorder=10)\n",
    "            \n",
    "            # Measuring girth as an array output (tuple)\n",
    "            girth = math.sqrt((xValues[-1] - xValues[0])**2 + (yValues[-1] - yValues[0])**2)\n",
    "            current_whale_girth.append(girth)\n",
    "           \n",
    "            \n",
    "            currentX = currentX + increment\n",
    "            \n",
    "        print(\"Image ID: \", img_id)\n",
    "        print(\"Current Whale's Girth\", current_whale_girth)\n",
    "        girth_measurements.append(current_whale_girth)\n",
    "        \n",
    "    # set axis limits\n",
    "        plt.xlim([minX - 100, maxX + 100])\n",
    "        plt.ylim([minY - 200, maxY + 200])\n",
    "        plt.show()\n",
    "    \n",
    "    return girth_measurements\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /home/clifgray/Code/Mask_RCNN/logs/whale20180613T0247/mask_rcnn_whale_0150.h5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: res4e_branch2b/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=557661, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res4a_branch2b/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'res4e_branch2b/random_uniform/RandomUniform', defined at:\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-28a39a227b42>\", line 1, in <module>\n    detection_results = run_cnn()\n  File \"<ipython-input-4-a1c4a3191c2b>\", line 5, in run_cnn\n    config=config)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1832, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1892, in build\n    stage5=True, train_bn=config.TRAIN_BN)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 194, in resnet_graph\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=chr(98 + i), train_bn=train_bn)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 114, in identity_block\n    name=conv_name_base + '2b', use_bias=use_bias)(x)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 432, in __call__\n    self.build(input_shapes[0])\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 138, in build\n    constraint=self.kernel_constraint)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/initializers.py\", line 218, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 4077, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: res4e_branch2b/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=557661, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res4a_branch2b/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: res4e_branch2b/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=557661, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res4a_branch2b/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-28a39a227b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetection_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a1c4a3191c2b>\u001b[0m in \u001b[0;36mrun_cnn\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2109\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                                                 weight_values[i]))\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: res4e_branch2b/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=557661, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res4a_branch2b/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'res4e_branch2b/random_uniform/RandomUniform', defined at:\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-28a39a227b42>\", line 1, in <module>\n    detection_results = run_cnn()\n  File \"<ipython-input-4-a1c4a3191c2b>\", line 5, in run_cnn\n    config=config)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1832, in __init__\n    self.keras_model = self.build(mode=mode, config=config)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1892, in build\n    stage5=True, train_bn=config.TRAIN_BN)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 194, in resnet_graph\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=chr(98 + i), train_bn=train_bn)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 114, in identity_block\n    name=conv_name_base + '2b', use_bias=use_bias)(x)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 432, in __call__\n    self.build(input_shapes[0])\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 138, in build\n    constraint=self.kernel_constraint)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/initializers.py\", line 218, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/clifgray/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 4077, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/clifgray/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: res4e_branch2b/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=557661, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res4a_branch2b/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "detection_results = run_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure(detection_results) #CNN appends length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_results = measure(mask_array) # lengths in pixels\n",
    "#print(manual_results)0cm-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lengths = convert_measurements(detection_results)\n",
    "manual_lengths = convert_measurements(manual_results)\n",
    "\n",
    "print(\"CNN Converted Lengths\", cnn_lengths)\n",
    "print(\"Manual Converted Lengths\", manual_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"girth\")\n",
    "cnn_girths = girth(detection_results, cnn_lengths, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
