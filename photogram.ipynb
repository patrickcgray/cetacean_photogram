{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN Species Photogrammetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy.ma as ma\n",
    "import scipy.misc\n",
    "import skimage.filters\n",
    "\n",
    "# Root directory of the project\n",
    "MASK_RCNN_DIR = os.path.abspath(\"../Mask_RCNN/\")\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(MASK_RCNN_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import whale\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = whale.WhaleConfig()\n",
    "WHALE_DIR = os.path.abspath(\"../photogram_data/\")\n",
    "\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "# Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "#config.display()\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\" # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 62\n",
      "Classes: ['BG', 'balaenoptera_musculus_body', 'balaenoptera_musculus_pectoral', 'megaptera_novaeangliae_body', 'megaptera_novaeangliae_pectoral', 'balaenoptera_acutorostrata_body', 'balaenoptera_acutorostrata_pectoral']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset to measure\n",
    "dataset = whale.WhaleDataset()\n",
    "dataset.load_whale(WHALE_DIR, \"test\")\n",
    "#dataset.load_whale(WHALE_DIR, \"test\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                          config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(weights_path=\"logs/whale20181014T1536/mask_rcnn_whale_0174.h5\", verbose=0):\n",
    "        \n",
    "    # Load weights\n",
    "    print(\"Loading weights \", weights_path)\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    print(\"Weights loaded.\")\n",
    "    \n",
    "    \n",
    "    detection_results = []\n",
    "    initial_time = time.perf_counter()\n",
    "    for image_id in dataset.image_ids:\n",
    "    \n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "\n",
    "        info = dataset.image_info[image_id]\n",
    "\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        \n",
    "        #detection_results.append([results, info, image_id])\n",
    "        detection_results.append([results, info['id'], image_id, {'class_ids' : gt_class_id, 'masks' : gt_mask, 'rois' : gt_bbox}])\n",
    "        if verbose:\n",
    "            print(\"Done detecting and masking image #:  \" + str(len(detection_results)))\n",
    "    \n",
    "    finish_time = time.perf_counter()\n",
    "    time_elapsed = finish_time - initial_time\n",
    "    if verbose:\n",
    "        print(\"\\n\")\n",
    "        print(time_elapsed, \"seconds elapsed while masking\", len(detection_results), \"images.\")\n",
    "        print((time_elapsed/len(detection_results), \"seconds per image.\"))\n",
    "    \n",
    "    return detection_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(body, visualize=False):\n",
    "    # based on https://alyssaq.github.io/2015/computing-the-axes-or-orientation-of-a-blob/\n",
    "    # and based on http://alyssaq.github.io/2015/visualising-matrices-and-affine-transformations-with-python/#rotating\n",
    "    xy_array = []\n",
    "    # get indexes of mask pixels\n",
    "    y, x = np.nonzero(body)\n",
    "    \n",
    "    # mean center the coords\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    coords = np.vstack([x, y])\n",
    "\n",
    "    # build covariance matreix and eigenvectors\n",
    "    cov = np.cov(coords)\n",
    "    evals, evecs = np.linalg.eig(cov)\n",
    "    \n",
    "    # sort eigenvalues\n",
    "    sort_indices = np.argsort(evals)[::-1]\n",
    "    x_v1, y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "    x_v2, y_v2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "    \n",
    "    if visualize is True:\n",
    "        # plot the major and minor axis of the whale mask\n",
    "        scale = 20\n",
    "        plt.plot(x, y, 'k.')\n",
    "\n",
    "        plt.plot([x_v1*-scale*2, x_v1*scale*2],\n",
    "         [y_v1*-scale*2, y_v1*scale*2], color='red')\n",
    "        plt.plot([x_v2*-scale, x_v2*scale],\n",
    "         [y_v2*-scale, y_v2*scale], color='blue')\n",
    "        plt.axis('equal')\n",
    "        plt.gca().invert_yaxis()  # Match the image system with origin at top left\n",
    "        plt.show()\n",
    "\n",
    "    # orient this along the horizontal axis\n",
    "    theta = np.tanh((x_v2)/(y_v2))  \n",
    "    \n",
    "    # TODO this is a hack, for some reason this doesn't work when theta is high or aka when the actual angle is small\n",
    "    if abs(theta) > 0.9:\n",
    "        theta = np.tanh((x_v1)/(y_v1))\n",
    "        theta = theta + 0.5 *math.pi\n",
    "    rotation_mat = np.matrix([[np.cos(theta), -np.sin(theta)],\n",
    "                      [np.sin(theta), np.cos(theta)]])\n",
    "    transformed_mat = rotation_mat * coords\n",
    "    \n",
    "    # plot the transformed blob\n",
    "    # these are the final transformed coords\n",
    "    x_transformed, y_transformed = transformed_mat.A\n",
    "\n",
    "    maxX = np.max(x_transformed)\n",
    "    minX = np.min(x_transformed)\n",
    "    maxY = np.max(y_transformed)\n",
    "    minY = np.min(y_transformed)\n",
    "\n",
    "\n",
    "    # Get corresonding Y values for minX and maxX\n",
    "    maxX_index = np.where(x_transformed == maxX)  # index of right-most point\n",
    "    rightY = float((y_transformed[maxX_index]))   # corresponding Y value\n",
    "\n",
    "\n",
    "    minX_index = np.where(x_transformed == minX)  # index of left-most point\n",
    "    leftY = float((y_transformed[minX_index]))    # corresponding Y value\n",
    "    \n",
    "    # Orient the mask correctly - flip so the fluke is on the right\n",
    "\n",
    "    # Get corresonding X values for maxY and minY\n",
    "\n",
    "    maxY_index = np.where(y_transformed == maxY) #index of top point\n",
    "    topX = float((x_transformed[maxY_index])) #corresponding X value\n",
    "\n",
    "\n",
    "    minY_index = np.where(y_transformed == minY) #index of bottom point\n",
    "    bottomX = float((x_transformed[minY_index])) #corresponding X value\n",
    "\n",
    "    # flip mask so fluke is on the right, if necessary\n",
    "    if (topX < 0 or bottomX < 0):\n",
    "        x_transformed = x_transformed*-1 \n",
    "    \n",
    "    xy_array = [x_transformed, y_transformed]\n",
    "    \n",
    "    \n",
    "    return xy_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(body_mask, visualize=False):\n",
    "    xy_array = pca(body_mask, visualize=visualize)\n",
    "    x_transformed = xy_array[0]\n",
    "    y_transformed = xy_array[1]\n",
    "\n",
    "    # Reassign max/min X values in case image was flipped during PCA\n",
    "    maxX = np.max(x_transformed) # Right-most point\n",
    "    minX = np.min(x_transformed) # Left-most point\n",
    "\n",
    "    # Get corresponding Y values for maxX and minX\n",
    "    maxX_index = np.where(x_transformed == maxX)  # index of right-most point\n",
    "    rightY = float((y_transformed[maxX_index]))   # corresponding Y value\n",
    "\n",
    "    minX_index = np.where(x_transformed == minX)  # index of left-most point\n",
    "    leftY = float((y_transformed[minX_index]))    # corresponding Y value\n",
    "\n",
    "    # TODO come up with a better solution here\n",
    "\n",
    "    # Draw a straight line across the mask\n",
    "\n",
    "    # Filter out points close to the midline of the mask (on the Y axis)\n",
    "    # TODO arbitrary lambda, might need to change later\n",
    "    lowEnough = list(filter(lambda y: y < (leftY + 0.5), y_transformed)) #above midline\n",
    "    yValues = list(filter(lambda y: y > (leftY - 0.5), lowEnough)) #below midline\n",
    "    yValues.sort()\n",
    "\n",
    "    # Get corresponding X values to draw the line\n",
    "\n",
    "    # List of appropriate indices\n",
    "    indices = []\n",
    "    for point in yValues:\n",
    "        index = int(np.where(y_transformed == point)[0])\n",
    "        indices.append(index)\n",
    "\n",
    "    xValues = [] # Corresponding X values\n",
    "    for index in indices:\n",
    "        xValues.append(x_transformed[index]) \n",
    "\n",
    "    xValues.sort()\n",
    "\n",
    "    # Use distance formula to measure the length from the midline\n",
    "    length = math.sqrt((xValues[-1] - xValues[0])**2 + (yValues[-1] - yValues[0])**2)\n",
    "    \n",
    "    return(length)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image could have multiple masks (body and pectoral) and multiple animals\n",
    "# Return all of the body masks\n",
    "\n",
    "def find_correct_masks(mask_list): \n",
    "    class_body_array = []\n",
    "    for index, class_id in enumerate(mask_list['class_ids']):\n",
    "        if class_id % 2 != 0: # all body class ids are odd numbers\n",
    "            if 'scores' in mask_list:\n",
    "                class_body_array.append([class_id, mask_list['masks'][:,:,index], mask_list['scores'][index]])\n",
    "            else:\n",
    "                class_body_array.append([class_id, mask_list['masks'][:,:,index]])\n",
    "    return(class_body_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_measurements(results_list, manual=False):\n",
    "    for detection_result in results_list:\n",
    "        detected_mask_list = detection_result[0][0]\n",
    "        gt_mask_list = detection_result[3]\n",
    "            \n",
    "        detected_body_list = find_correct_masks(detected_mask_list)  \n",
    "        gt_body_list = find_correct_masks(gt_mask_list)\n",
    "\n",
    "        detected_body_lengths = []\n",
    "        for class_id_body in detected_body_list:\n",
    "            # adding class id, body length, and scores from CNN\n",
    "            detected_body_lengths.append([class_id_body[0], measure(class_id_body[1]), class_id_body[2]])\n",
    "        \n",
    "        gt_body_lengths = []\n",
    "        for class_id_body in gt_body_list:\n",
    "            gt_body_lengths.append([class_id_body[0], measure(class_id_body[1])])\n",
    "       \n",
    "        detection_result.append(detected_body_lengths)\n",
    "        detection_result.append(gt_body_lengths)\n",
    "        # detection_results is now [results, info['id'], image_id, gt_mask_dict, [class_id, cnn_lengths, cnn_scores], [class_id, gt_lengths]]\n",
    "            \n",
    "    return(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_from_csv(csv_fn):\n",
    "    measurements = pd.read_csv(csv_fn)\n",
    "        \n",
    "    blue_measurements = measurements.loc[measurements[\"Whale\"].str.contains(\"Bm\")] \n",
    "    blue_measurements = blue_measurements.reset_index(drop=True)\n",
    "    \n",
    "    humpback_measurements = measurements.loc[measurements[\"Whale\"].str.contains(\"Mn\")] \n",
    "    humpback_measurements = humpback_measurements.reset_index(drop=True)\n",
    "    \n",
    "    minke_measurements = measurements.loc[measurements[\"Whale\"].str.contains(\"Bb\")] \n",
    "    minke_measurements = minke_measurements.reset_index(drop=True)\n",
    "\n",
    "    return(blue_measurements, humpback_measurements, minke_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_meters(pixels, size_factor, pixel_size, focal_length, total_altitude):\n",
    "    adjusted_pixel_count = pixels * size_factor\n",
    "    return(adjusted_pixel_count * pixel_size/focal_length * total_altitude)\n",
    "    \n",
    "\n",
    "def convert_measurements(merged_df, org_img_size=(6000.0, 4000.0)):\n",
    "    all_lengths = []\n",
    "\n",
    "    # imaged were downsized from 6000 as a max dimension to 1024 as a max dimension so pixels are 5x as large in meters\n",
    "    pixel_size_factor =  org_img_size[0] / 1024.0\n",
    "    \n",
    "    for i, row in merged_df.iterrows():\n",
    "        det_length = pixel_to_meters(row['detected_pix_len'], pixel_size_factor, row['Pixel size'], row[\"Focal length (mm)\"], row[\"Total Altitude\"])   \n",
    "        merged_df.at[i,'detected_len'] = det_length\n",
    "        \n",
    "        gt_length = pixel_to_meters(row['gt_pix_len'], pixel_size_factor, row['Pixel size'], row[\"Focal length (mm)\"], row[\"Total Altitude\"])   \n",
    "        merged_df.at[i,'gt_len'] = gt_length\n",
    "    \n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(appended_detections, measurements_csv_fn):\n",
    "    detections_df = pd.DataFrame(columns=['Image','detected_class','detected_pix_len','gt_class','gt_pix_len', 'detection_score', 'IoU'])\n",
    "    for index, img in enumerate(appended_detections):\n",
    "        try:\n",
    "            longest_length = 0\n",
    "            longest_mask_index = None\n",
    "            longest_detection = None\n",
    "            for mask_index, detection in enumerate(img[4]): # this is the detected mask class and can have multiple\n",
    "                # take the longest mask\n",
    "                if detection[1] > longest_length:\n",
    "                    longest_detection = detection\n",
    "                    longest_length = detection[1]\n",
    "                    longest_mask_index = mask_index\n",
    "            \n",
    "            img.append([longest_mask_index, longest_length])\n",
    "            \n",
    "            gt_longest_length = 0\n",
    "            gt_longest_mask_index = None\n",
    "            gt_longest_detection = None\n",
    "            for mask_index, detection in enumerate(img[5]): # this is the gt mask class and can have multiple\n",
    "                # take the longest mask\n",
    "                if detection[1] > gt_longest_length:\n",
    "                    gt_longest_detection = detection\n",
    "                    gt_longest_length = detection[1]\n",
    "                    gt_longest_mask_index = mask_index\n",
    "\n",
    "            #print(img[0][0]['masks'][longest_detection])\n",
    "            \n",
    "            #\"\"\"\n",
    "            ap = utils.compute_ap_range(np.array([img[3]['rois'][gt_longest_mask_index]]), \n",
    "                                        np.array([img[3]['class_ids'][gt_longest_mask_index]]), \n",
    "                                        np.array([img[3]['masks'][gt_longest_mask_index]]),\n",
    "                                        np.array([img[0][0]['rois'][longest_mask_index]]), \n",
    "                                        np.array([img[0][0]['class_ids'][longest_mask_index]]), \n",
    "                                        np.array([img[0][0]['scores'][longest_mask_index]]), \n",
    "                                        np.array([img[0][0]['masks'][longest_mask_index]]), \n",
    "                                        iou_thresholds=None)\n",
    "                        \n",
    "            iou_array = utils.compute_overlaps_masks(img[3]['masks'], img[0][0]['masks'])\n",
    "            iou = iou_array.max()\n",
    "            #print('IOU is: ', iou)\n",
    "            \n",
    "            detections_df = detections_df.append({\"Image\": img[1], \"detected_class\": longest_detection[0], \n",
    "                                \"detected_pix_len\": longest_detection[1], 'gt_class' : img[5][0][0],\n",
    "                                \"gt_pix_len\" : img[5][0][1], 'detection_score' : longest_detection[2], 'IoU' : iou},\n",
    "                                ignore_index=True)\n",
    "        except IndexError: # in case a detection was not made\n",
    "            print(\"Index error\")\n",
    "            pass\n",
    "        except TypeError: # also in case a detection was not made\n",
    "            print(\"TypeError\")\n",
    "            pass\n",
    "        \n",
    "    measurements = pd.read_csv(measurements_csv_fn)\n",
    "    \n",
    "    merged_df = detections_df.merge(measurements,on='Image', how='inner') #.dropna(subset=['id'])\n",
    "    \n",
    "    return(merged_df)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(body_mask, visualize=False):\n",
    "    xy_array = pca(body_mask, visualize=visualize)\n",
    "    x_transformed = xy_array[0]\n",
    "    y_transformed = xy_array[1]\n",
    "\n",
    "    # Reassign max/min X values in case image was flipped during PCA\n",
    "    maxX = np.max(x_transformed) # Right-most point\n",
    "    minX = np.min(x_transformed) # Left-most point\n",
    "\n",
    "    # Get corresponding Y values for maxX and minX\n",
    "    maxX_index = np.where(x_transformed == maxX)  # index of right-most point\n",
    "    rightY = float((y_transformed[maxX_index]))   # corresponding Y value\n",
    "\n",
    "    minX_index = np.where(x_transformed == minX)  # index of left-most point\n",
    "    leftY = float((y_transformed[minX_index]))    # corresponding Y value\n",
    "\n",
    "    # TODO come up with a better solution here\n",
    "\n",
    "    # Draw a straight line across the mask\n",
    "\n",
    "    # Filter out points close to the midline of the mask (on the Y axis)\n",
    "    # TODO arbitrary lambda, might need to change later\n",
    "    lowEnough = list(filter(lambda y: y < (leftY + 0.5), y_transformed)) #above midline\n",
    "    yValues = list(filter(lambda y: y > (leftY - 0.5), lowEnough)) #below midline\n",
    "    yValues.sort()\n",
    "\n",
    "    # Get corresponding X values to draw the line\n",
    "\n",
    "    # List of appropriate indices\n",
    "    indices = []\n",
    "    for point in yValues:\n",
    "        index = int(np.where(y_transformed == point)[0])\n",
    "        indices.append(index)\n",
    "\n",
    "    xValues = [] # Corresponding X values\n",
    "    for index in indices:\n",
    "        xValues.append(x_transformed[index]) \n",
    "\n",
    "    xValues.sort()\n",
    "\n",
    "    # Use distance formula to measure the length from the midline\n",
    "    length = math.sqrt((xValues[-1] - xValues[0])**2 + (yValues[-1] - yValues[0])**2)\n",
    "    \n",
    "    if visualize:    \n",
    "        #plt.plot(x_transformed, y_transformed, alpha = 0.5)\n",
    "        plt.plot(x_transformed, y_transformed, 'g.', zorder=0)\n",
    "\n",
    "        # set axis limits\n",
    "        plt.xlim([minX - 30, maxX + 30])\n",
    "        plt.ylim([leftY - 175, rightY + 175])\n",
    "\n",
    "        #Plot the first and last points from the list, use this for length\n",
    "\n",
    "        #plt.scatter(xValues[0], yValues[0], zorder=10)\n",
    "        #plt.scatter(xValues[-1], yValues[-1], zorder=10)\n",
    "        plt.scatter(xValues, yValues, zorder=10)\n",
    "        plt.show()\n",
    "    \n",
    "    return(length)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /home/clifgray/Code/cetacean_photogram/logs/whale20181014T1536/mask_rcnn_whale_0174.h5\n",
      "Re-starting from epoch 174\n",
      "Weights loaded.\n"
     ]
    }
   ],
   "source": [
    "detection_results = run_cnn(weights_path = 'logs/whale20181014T1536/mask_rcnn_whale_0174.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_measurements(detection_results) # CNN appends length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df = create_df(detection_results, '../photogram_data/whale_measurements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_measurements(detection_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(detection_df['Total Length (m)'], detection_df['detected_len'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
